# -*- coding: utf-8 -*-
"""Sistem Rekomendasi_Nida Annisa Sholeha.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tig647Z9kiPFFMghe-ssCAah-0G9wpZu

# Proyek Sistem Rekomendasi: Anime Recommendations Database
- **Dataset** : https://www.kaggle.com/datasets/CooperUnion/anime-recommendations-database
- **Nama** : Nida Annisa Sholeha
- **Email** : nasa6annisa@gmail.com
- **ID Dicoding** : Nidaannisa19

# **Import Seluruh Library**
Tahap ini bertujuan untuk mengimpor seluruh pustaka (libraries) Python yang akan digunakan dalam proyek analisis data dan pemodelan machine learning ini. Setiap pustaka memiliki peran spesifik dalam memfasilitasi berbagai tahapan proyek.
"""

# Import Libraries
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import os
import json
import nltk
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import linear_kernel, cosine_similarity
from sklearn.model_selection import train_test_split
from scipy.sparse import csr_matrix
from sklearn.metrics import mean_squared_error
from collections import defaultdict

# Download NLTK resources (jalankan sekali jika belum)
nltk.download('punkt')
nltk.download('stopwords')

# Mount Google Drive (Colab)
from google.colab import files
from google.colab import drive
drive.mount('/content/drive')

uploaded = files.upload()

# Membuat direktori .kaggle
os.makedirs('/root/.kaggle', exist_ok=True)
!mv kaggle.json /root/.kaggle/
!chmod 600 /root/.kaggle/kaggle.json
!ls -l /root/.kaggle/

"""Tahap ini bertujuan untuk mengkonfigurasi otentikasi dengan Kaggle API. Kaggle API memungkinkan pengguna untuk berinteraksi dengan data Kaggle, mengunduh dataset, berpartisipasi dalam kompetisi, dan lainnya secara programatik. Langkah-langkah ini melibatkan pembuatan direktori `.kaggle` di direktori `/root/` sebagai lokasi standar untuk file kredensial API. Perintah `!mv kaggle.json /root/.kaggle/` digunakan untuk memindahkan file `kaggle.json` yang berisi kunci API pengguna dari lokasi saat ini ke direktori `.kaggle`. Selanjutnya, perintah `!chmod 600 /root/.kaggle/kaggle.json` diterapkan untuk mengatur izin akses file `kaggle.json` menjadi hanya dapat dibaca dan ditulis oleh pemiliknya, sebagai langkah keamanan yang disarankan. Terakhir, perintah `!ls -l /root/.kaggle/` digunakan untuk memverifikasi keberhasilan pemindahan file dan memeriksa izin aksesnya."""

!kaggle datasets download -d CooperUnion/anime-recommendations-database # Mengunduh dataset dari kaggle

!unzip anime-recommendations-database.zip # Mengekstrak dataset

"""# **Data Preparation**

# **Data Loading**

Tahap ini bertujuan untuk memuat dataset yang diperlukan ke dalam lingkungan kerja agar data tersebut dapat diakses dan diproses lebih lanjut. Data yang berhasil dimuat kemudian disimpan dalam struktur data yang sesuai untuk memudahkan manipulasi, eksplorasi, dan analisis pada tahapan berikutnya
"""

anime_df_original = pd.read_csv('/content/anime.csv')

rating_df_original = pd.read_csv('/content/rating.csv')

df_anime = anime_df_original.copy()
df_rating = rating_df_original.copy()

"""# **Data Understanding**

- Proyek ini menggunakan dataset [Anime Recommendations Database](https://www.kaggle.com/datasets/CooperUnion/anime-recommendations-database) yang bersumber dari [Kaggle](https://www.kaggle.com/datasets/CooperUnion/anime-recommendations-database). Dataset terdiri dari dua file .csv yaitu anime.csv dan rating.csv.

- Dataset anime.csv berisi informasi mengenai berbagai anime, seperti judul, genre, tipe, episode, rating, dan anggota. Dataset ini memiliki 12294 baris dan 7 kolom. Kondisi data menunjukkan adanya missing values pada kolom **genre**.

- Dataset rating.csv berisi informasi mengenai rating yang diberikan pengguna untuk anime-anime tersebut. Setiap baris menunjukkan rating seorang pengguna untuk anime tertentu. Dataset ini memiliki 7813737 baris dan 3 kolom. Kondisi data menunjukkan bahwa terdapat nilai "-1" pada kolom **rating** yang mengindikasikan bahwa pengguna tidak benar-benar memberikan rating pada anime tersebut.

# **Exploratory Data Analysis**

Tahapan EDA (Exploratory Data Analysis) bertujuan memahami karakteristik dari dataset, mengidentifikasi pola, hubungan antar variabel dan visualisasi data untuk mendapatkan insight awal dataset agar dapat menjawab rumusan masalah:
1. Bagaimana cara membantu pengguna menemukan anime yang sesuai dengan preferensi mereka di antara banyaknya pilihan yang tersedia di platform streaming?
2. Bagaimana sistem rekomendasi dapat meningkatkan user engagement dan retensi pengguna pada platform streaming anime?
3. Bagaimana sistem rekomendasi dapat dimanfaatkan untuk memperluas eksposur anime yang kurang populer kepada audiens yang relevan?
"""

df_anime.head()

df_rating.head()

"""Variabel-variabel pada Anime Recommendations Database dataset adalah sebagai berikut:
1. **Dataset anime**
- anime_id = ID unik dari setiap anime.
- name = Judul anime.
- genre = genre anime.
- type = Tipe tayang anime, seperti TV, OVA, etc.
- episodes = Banyaknya episode setiap anime.
- rating = Rata-rata rating setiap anime terhadap jumlah user yang memberi rating.
- members = Jumlah anggota komunitas setiap anime.

2. **Dataset anime_rating**
- user_id = ID unik dari setiap user
- anime_id = ID dari anime yang diberi peringkat oleh user
- rating = Rating yang diberikan oleh user.


"""

df_anime.info()

df_rating.info()

"""Berdasarkan output ini, berikut adalah beberapa insight yang bisa didapatkan:
  - Ukuran Data: DataFrame df_rating jauh lebih besar daripada df_anime, menunjukkan bahwa ada banyak rating dari pengguna untuk anime.
  - Tipe Data: Kolom episodes pada df_anime memiliki tipe data object, yang tidak biasa untuk kolom yang berisi jumlah episode. Ini menunjukkan mungkin ada nilai non-numerik dalam kolom ini (misalnya, tanda tanya atau string).
  - Missing Value: DataFrame df_anime memiliki nilai yang hilang di kolom genre, type, dan rating, yang perlu ditangani dalam tahap persiapan data.
"""

df_rating.duplicated().sum()

df_anime.describe()

"""Data anime berisi informasi tentang 12294 judul anime. Informasi yang tersedia meliputi ID anime, judul, genre, jenis, jumlah episode, rating rata-rata (yang berkisar antara 1.67 hingga 10), dan jumlah penggemar. Jumlah penggemar bervariasi sangat luas, dari 5 hingga lebih dari 1 juta yang menunjukkan perbedaan besar dalam popularitas anime."""

df_rating.describe()

"""Data rating (df_rating) berisi 7.813.737 rating yang diberikan pengguna untuk anime. Setiap rating dikaitkan dengan ID pengguna dan ID anime. Rating berkisar antara -1 hingga 10, dengan nilai rata-rata sekitar 6. Nilai -1 mungkin memiliki arti khusus seperti menunjukkan bahwa pengguna telah menonton anime tersebut tetapi tidak memberikan rating eksplisit."""

# Ringkasan statistik dari kolom bertipe objek di df_anime
object_summary = df_anime.describe(include=['object'])

# Menampilkan ringkasan
print(object_summary)

"""Analisis terhadap kolom-kolom bertipe objek pada dataset df_anime menunjukkan bahwa mayoritas judul anime bersifat unik. Kolom genre memiliki variasi kombinasi yang signifikan, dengan "Hentai" sebagai genre yang paling sering muncul. Tipe anime yang paling dominan adalah "TV". Lebih lanjut, teridentifikasi bahwa jumlah episode terbanyak adalah satu, mengindikasikan prevalensi anime berformat Movie atau OVA. Di samping itu, ditemukan adanya sejumlah kecil nilai yang hilang pada kolom genre dan type, yang memerlukan penanganan lebih lanjut dalam tahap persiapan data."""

# Memeriksa jumlah nilai yang hilang di setiap kolom
print("Jumlah nilai yang hilang sebelum penanganan:")
print(df_anime.isnull().sum())

"""Ada missing value yang harus dibersihkan pada kolom genre, type dan rating."""

# Memeriksa jumlah data duplikat df_anime
print("Jumlah data duplikat sebelum penanganan:", df_anime.duplicated().sum())

"""df_anime tidak memiliki nilai duplikat"""

# Menghapus baris yang memiliki nilai yang hilang pada kolom 'genre', dan 'type'
df_anime = df_anime.dropna(subset=['genre', 'type'])

"""Menangani missing value dengan metode dropna"""

# Memeriksa modus di kolom rating
df_anime['rating'].mode()

# Mengisi missing value di kolom rating dengan modus
df_anime['rating'].fillna(df_anime['rating'].mode()[0], inplace=True)

df_anime[df_anime['rating']==6.0].sum()

"""Menangani missing value pada kolom rating dengan melihat modus dan mengisinya menggunakan nilai yang paling sering muncul (modus)"""

# Memeriksa kembali jumlah nilai yang hilang dan data duplikat setelah penanganan
print("Jumlah nilai yang hilang setelah penanganan:")
print(df_anime.isnull().sum())
print("Jumlah data duplikat setelah penanganan:", df_anime.duplicated().sum())

"""## **Univariate** **Analysis**"""

# Univariate Analysis df_anime

plt.figure(figsize=(10, 6))
sns.histplot(df_anime['rating'].dropna(), bins=30, kde=True)
plt.title('Distribusi Rating Anime')
plt.xlabel('Rating')
plt.ylabel('Jumlah Anime')
plt.show()
print(f"Rata-rata rating: {df_anime['rating'].mean():.2f}")
print(f"Median rating: {df_anime['rating'].median():.2f}")

"""Visualisasi ini menampilkan sebagian besar anime memiliki rating antara 6 hingga 8, dengan puncak distribusi berada di sekitar **rating 7**. Distribusi ini cenderung mendekati normal, meskipun *sedikit* miring ke kiri (positively skewed). Rata-rata rating anime adalah 6.47, sementara median rating adalah 6.55. Ini menunjukkan bahwa nilai rata-rata dan median hampir sama, mengkonfirmasi **distribusi yang cukup simetris**."""

# Distribusi Tipe Anime
plt.figure(figsize=(8, 5))
sns.countplot(data=df_anime, y='type', order=df_anime['type'].value_counts().index)
plt.title('Distribusi Tipe Anime')
plt.xlabel('Jumlah Anime')
plt.ylabel('Tipe')
plt.show()
print("\nJumlah Anime per Tipe:")
print(df_anime['type'].value_counts())

"""Tipe TV adalah yang paling banyak jumlahnya, diikuti oleh OVA dan Movie. Tipe Special juga memiliki jumlah yang cukup signifikan. Sementara itu, tipe ONA (Original Net Animation) dan Music memiliki jumlah anime yang jauh lebih sedikit dibandingkan tipe lainnya. Ini menunjukkan bahwa serial anime televisi merupakan format yang paling umum dalam dataset ini."""

# Memeriksa tipe data kolom 'episodes'
print("Tipe data kolom 'episodes' sebelum perbaikan:")
print(df_anime['episodes'].dtype)

# Memeriksa nilai non-numerik dalam kolom 'episodes'
non_numeric_episodes = df_anime[pd.to_numeric(df_anime['episodes'], errors='coerce').isna()]['episodes'].unique()
print("\nNilai non-numerik dalam kolom 'episodes':")
print(non_numeric_episodes)

# Mengubah nilai non-numerik menjadi NaN, lalu dikonversi menjadi numerik
df_anime['episodes'] = pd.to_numeric(df_anime['episodes'], errors='coerce')

# Menghapus baris yang memiliki NaN di kolom 'episodes'
df_anime = df_anime.dropna(subset=['episodes'])

print("\nTipe data kolom 'episodes' setelah perbaikan:")
print(df_anime['episodes'].dtype)

"""Pada tahap Data Preparation, ditemukan adanya nilai non-numerik pada kolom 'episodes' yang menghambat proses Exploratory Data Analysis (EDA), terutama saat mencoba membuat visualisasi atau perhitungan. Untuk mengatasi ini, dilakukan pembersihan data dengan mengidentifikasi nilai non-numerik dan mengubahnya menjadi NaN (Not a Number), kemudian baris yang tidak valid tersebut dihapus. Langkah ini memastikan kolom 'episodes' memiliki tipe data numerik yang konsisten, sehingga data siap untuk analisis dan pemodelan lebih lanjut."
"""

# Visualisasi Distribusi Jumlah Episode (Under 200)
plt.figure(figsize=(10, 6))
sns.histplot(df_anime['episodes'][df_anime['episodes'] < 200].dropna(), bins=50, kde=True)
plt.title('Distribusi Jumlah Episode (dibawah 200)')
plt.xlabel('Jumlah Episode')
plt.ylabel('Jumlah Anime')
plt.show()
print(f"Rata-rata episode: {df_anime['episodes'].mean():.2f}")
print(f"Median episode: {df_anime['episodes'].median():.2f}")

"""- Pada tahap EDA univariat, saat memeriksa kolom 'episodes', saya menemukan perlunya pembersihan dan konversi tipe data terlebih dahulu agar visualisasi distribusinya dapat dilakukan dengan tepat. Langkah-langkah data preparation seperti penanganan nilai non-numerik dan perubahan tipe data kemudian diimplementasikan sebelum menghasilkan histogram.

- Hasil visualisasi ini menampilkan distribusi jumlah episode anime dengan batasan maksimal 200 episode. Terlihat bahwa sebagian besar anime memiliki jumlah episode yang sangat sedikit, dengan puncak frekuensi berada di sekitar 1 episode. Distribusi ini menunjukkan kemiringan positif yang sangat kuat, di mana sebagian besar data terkonsentrasi di nilai-nilai rendah, dan hanya sedikit anime yang memiliki jumlah episode yang lebih banyak. Rata-rata jumlah episode adalah 12.43, sementara median jumlah episode hanya 2.00. Perbedaan yang signifikan antara rata-rata dan median ini semakin mengkonfirmasi adanya skewness dan menunjukkan bahwa rata-rata dipengaruhi oleh sejumlah kecil anime dengan jumlah episode yang sangat banyak.

"""

# Analisis Genre
genre_counts = df_anime['genre'].str.split(', ', expand=True).stack().value_counts().nlargest(10)
plt.figure(figsize=(12, 7))
sns.barplot(x=genre_counts.values, y=genre_counts.index, palette='viridis')
plt.title('Top 10 Genre Anime')
plt.xlabel('Jumlah Anime')
plt.ylabel('Genre')
plt.show()
print("\nTop 10 Genre Anime:")
print(genre_counts)

"""Visualisasi ini menampilkan 10 genre anime teratas berdasarkan jumlah kemunculannya. Terlihat jelas bahwa Comedy adalah genre yang paling dominan, diikuti oleh Action di posisi kedua. Genre-genre seperti Adventure, Fantasy, Sci-Fi, dan Drama juga memiliki jumlah yang cukup signifikan dan relatif berdekatan. Sementara itu, genre Shounen, Kids, Romance, dan Slice of Life memiliki jumlah anime yang lebih sedikit dibandingkan enam genre teratas. Secara keseluruhan, grafik ini memberikan gambaran tentang popularitas dan prevalensi berbagai genre dalam dataset anime."""

# Visualiasasi Rating Pengguna
plt.figure(figsize=(8, 6))
sns.histplot(df_rating['rating'], bins=11, discrete=True)
plt.title('Distribusi Rating Pengguna')
plt.xlabel('Rating')
plt.ylabel('Jumlah Rating')
plt.show()
print("\nJumlah Rating per Nilai:")
print(df_rating['rating'].value_counts().sort_index())

"""Terlihat adanya puncak frekuensi yang sangat tinggi pada nilai rating -1. Setelah itu, frekuensi rating cenderung meningkat dari nilai 1 hingga mencapai puncak kedua pada nilai rating 8. Rating 7 dan 9 juga memiliki frekuensi yang tinggi, diikuti oleh rating 10. Rating 1 hingga 5 memiliki frekuensi yang relatif lebih rendah dibandingkan rating di atas 5. Distribusi ini menunjukkan bahwa sebagian besar interaksi pengguna ditandai dengan nilai -1 (yang mungkin mengindikasikan watched atau tidak relevan) dan rating positif di atas 5, dengan preferensi yang kuat pada rating 8.

## **Bivariate Analysis**
"""

# Rata-Rata Rating berdasarkan Tipe Anime
plt.figure(figsize=(10, 6))
sns.boxplot(data=df_anime, x='rating', y='type')
plt.title('Rata-rata Rating Berdasarkan Tipe Anime')
plt.xlabel('Rating')
plt.ylabel('Tipe')
plt.show()

"""Visualisasi ini menampilkan perbandingan distribusi rating berdasarkan tipe anime menggunakan boxplot. Setiap boxplot menunjukkan sebaran rating untuk tipe anime yang berbeda (Movie, TV, OVA, Special, Music, ONA).

Terlihat bahwa secara umum, tidak ada perbedaan dramatis dalam rating rata-rata antar tipe anime, karena median (garis tengah kotak) untuk semua tipe berada di kisaran rating 6 hingga 7. Namun, terdapat perbedaan dalam sebaran rating (panjang kotak) dan jumlah outlier (lingkaran di luar whisker).

Misalnya, tipe Movie dan TV cenderung memiliki sebaran rating yang lebih luas dibandingkan tipe Music dan ONA. Selain itu, beberapa tipe seperti OVA dan Special memiliki lebih banyak outlier di kedua ujung distribusi rating, yang mengindikasikan adanya lebih banyak anime dengan rating yang sangat tinggi atau sangat rendah dalam kategori tersebut dibandingkan tipe lainnya.
"""

# Hubungan Jumlah Episode dan Rating
plt.figure(figsize=(10, 6))
sns.scatterplot(data=df_anime[df_anime['episodes'] < 500], x='episodes', y='rating')
plt.title('Hubungan antara Jumlah Episode dan Rating')
plt.xlabel('Jumlah Episode')
plt.ylabel('Rating')
plt.show()

"""- Sebagian besar anime pendek atau berdurasi sedang: Mayoritas anime memiliki jumlah episode di bawah 50.
- Tidak ada korelasi kuat antara jumlah episode dan rating secara keseluruhan: Panjang serial anime tidak secara langsung menjamin rating yang lebih tinggi atau lebih rendah.
- Anime rating rendah cenderung tidak panjang: Anime dengan rating yang sangat buruk jarang memiliki ratusan episode, mungkin karena kurangnya popularitas atau kualitas yang tidak menarik minat penonton dalam jangka panjang.
- Variasi rating tinggi pada anime pendek: Anime dengan jumlah episode sedikit pun dapat memiliki rating yang sangat tinggi, menunjukkan kualitas cerita atau eksekusi yang baik meskipun singkat.

## **Multivariate Analysis**
"""

# Split genre dan stack
genre_exploded = df_anime['genre'].str.split(', ', expand=True)
genre_stacked = genre_exploded.stack().str.strip()
genre_stacked = genre_stacked[genre_stacked != '']

# Menggabungkan dengan rating
anime_genre_rating = df_anime[['name', 'rating']].copy()
anime_genre_rating['genre'] = df_anime['genre'].str.split(', ')
anime_genre_rating_exploded = anime_genre_rating.explode('genre')
anime_genre_rating_exploded['genre'] = anime_genre_rating_exploded['genre'].str.strip()

# Groupby genre dan menghitung rata-rata rating
genre_rating_filtered = anime_genre_rating_exploded.groupby('genre')['rating'].mean().sort_values(ascending=False).head(10)

plt.figure(figsize=(12, 7))
sns.barplot(x=genre_rating_filtered.values, y=genre_rating_filtered.index, palette='plasma')
plt.title('Rata-rata Rating untuk Top 10 Genre (Alternative)')
plt.xlabel('Rata-rata Rating')
plt.ylabel('Genre')
plt.show()
print("\nRata-rata Rating untuk Top 10 Genre (Alternative):")
print(genre_rating_filtered)

"""- Kode ini berfungsi untuk menganalisis dan memvisualisasikan rata-rata rating untuk setiap genre anime.

- Prosesnya dimulai dengan memisahkan genre-genre yang ada di kolom 'genre' menjadi entri-entri terpisah, di mana satu anime bisa memiliki banyak baris jika ia memiliki beberapa genre. Setelah itu, kode menggabungkan informasi genre yang sudah dipisah ini dengan data rating anime.

- Selanjutnya, dihitung rata-rata rating untuk setiap genre. Dari hasil ini, 10 genre teratas dengan rata-rata rating tertinggi kemudian dipilih. Terakhir, data ini divisualisasikan dalam bentuk bar plot untuk menunjukkan perbandingan rata-rata rating antar genre, sekaligus mencetak datanya.

- Hasil visualisasi yaitu Josei memiliki rata-rata rating tertinggi, diikuti oleh Thriller dan Mystery. Genre Police juga memiliki rata-rata rating yang cukup tinggi. Sementara itu, genre seperti Shounen, Psychological, Military, Romance, Supernatural, dan Drama memiliki rata-rata rating yang sedikit lebih rendah dan relatif berdekatan. Secara keseluruhan, rata-rata rating untuk 10 genre teratas ini berada di atas 6.9, menunjukkan bahwa genre-genre ini umumnya mendapatkan penilaian yang baik dari pengguna. Perbedaan rata-rata rating antar genre teratas ini tidak terlalu signifikan, namun Josei dan Thriller tampak sedikit lebih unggul dalam hal rata-rata rating.

# **Penggabungan Dataset**
"""

# Menggabungkan data rating dengan data anime
merged_df = pd.merge(df_rating, df_anime, on='anime_id', suffixes=['_user', '_anime'])

# Pra-pemrosesan genre untuk Content-Based Filtering (Tokenisasi Dasar + Stop Words Removal)
stop_words = set(stopwords.words('english'))
def simple_process_text_with_stopwords(text):
    words = [word.lower() for word in text.split(', ')]
    words = [w for w in words if not w in stop_words]
    return ' '.join(words)
df_anime['processed_genre'] = df_anime['genre'].apply(simple_process_text_with_stopwords)

"""Kode ini menggabungkan data rating dan anime berdasarkan anime_id, menghasilkan merged_df. Kemudian, kode ini memproses kolom genre untuk Content-Based Filtering dengan membuat kolom baru processed_genre. Proses ini melibatkan memecah string genre menjadi kata-kata, mengubahnya menjadi huruf kecil, dan menghilangkan stop words. Hasilnya adalah representasi genre yang lebih bersih untuk analisis kemiripan.

# **Model Development**

## **Content Based Filtering**
"""

# Inisialisasi TF-IDF Vectorizer
tfidf = TfidfVectorizer(stop_words='english')

# Menghasilkan matriks TF-IDF dari genre yang sudah diproses
tfidf_matrix = tfidf.fit_transform(df_anime['processed_genre'])

# Cosine similarity
cosine_sim_content = linear_kernel(tfidf_matrix, tfidf_matrix)
indices_content = pd.Series(df_anime.index, index=df_anime['name']).drop_duplicates()

def get_content_based_recommendations(title, cosine_sim=cosine_sim_content, df_anime=df_anime, indices=indices_content, k=5):
    if title not in indices:
        print(f"Anime '{title}' tidak ditemukan dalam dataset.")
        return None
    idx = indices[title]
    sim_scores = list(enumerate(cosine_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1:k+1]
    anime_indices = [i[0] for i in sim_scores]
    recommendations_df = df_anime[['name', 'genre']].iloc[anime_indices].copy()
    recommendations_df['similarity_score'] = [i[1] for i in sim_scores]
    return recommendations_df

print("\nContoh Rekomendasi Content-Based untuk 'Death Note':")
print(get_content_based_recommendations("Death Note"))

"""- Kode ini mengimplementasikan sistem rekomendasi Content-Based Filtering berdasarkan genre anime. Pertama, menggunakan TF-IDF untuk mengubah genre anime menjadi vektor numerik. Kemudian, menghitung kemiripan antar anime berdasarkan vektor genre menggunakan cosine similarity. Terakhir, fungsi get_content_based_recommendations mengambil judul anime dan mengembalikan k anime paling mirip berdasarkan genre.

- Output menunjukkan 5 anime teratas yang direkomendasikan untuk "Death Note" berdasarkan kemiripan genre. "Death Note Rewrite" memiliki skor similaritas tertinggi (1.000000), diikuti oleh "Mousou Dairinin", "Higurashi no Naku Koro ni Kai", "Higurashi no Naku Koro ni Rei", dan "Mirai Nikki (TV)", beserta skor similaritas dan genre masing-masing. Rekomendasi ini didasarkan pada analisis kemiripan teks genre antar anime.

## **Collaborative Filtering**
"""

# Membatasi pengguna dan anime dengan jumlah rating minimal
user_counts = merged_df['user_id'].value_counts()
valid_users = user_counts[user_counts >= 50].index
anime_counts = merged_df['name'].value_counts()
valid_animes = anime_counts[anime_counts >= 50].index

# Melakukan filter DataFrame berdasarkan pengguna dan anime yang valid
filtered_merged_df = merged_df[merged_df['user_id'].isin(valid_users) & merged_df['name'].isin(valid_animes)]

# Membuat pivot table dari filtered_merged_df
try:
    # Membuat matriks user-item
    user_item_matrix = filtered_merged_df.pivot_table(index='user_id', columns='name', values='rating_user').fillna(0)

    # Membuat matriks sparse untuk efisiensi memori
    sparse_matrix = csr_matrix(user_item_matrix)

    # Menghitung cosine similarity antar item
    item_similarity_cf = cosine_similarity(sparse_matrix.T)

    # Membuat DataFrame dari matriks similarity item
    item_similarity_df_cf = pd.DataFrame(item_similarity_cf, index=user_item_matrix.columns, columns=user_item_matrix.columns)

    def get_collaborative_recommendations(anime_name, similarity_matrix=item_similarity_df_cf, k=5):
        if anime_name not in similarity_matrix.index:
            print(f"Anime '{anime_name}' tidak ditemukan dalam data rating setelah filtering.")
            return None
        similar_animes = similarity_matrix[anime_name].sort_values(ascending=False)[1:k+1]
        return similar_animes

    print("\nContoh Rekomendasi Collaborative Filtering (setelah membatasi pengguna dan anime) untuk 'Death Note':")
    print(get_collaborative_recommendations("Death Note"))

except MemoryError as e:
    print(f"Error kehabisan memori saat membuat matriks user-item setelah membatasi pengguna dan anime: {e}")

"""- Kode ini mengimplementasikan sistem rekomendasi Collaborative Filtering berbasis kemiripan item. Pertama, kode membatasi dataset hanya pada pengguna dan anime yang memiliki minimal 50 rating untuk mengurangi sparsity. Kemudian, kode membuat matriks user-item dari rating pengguna terhadap anime. Matriks ini diubah menjadi format sparse untuk efisiensi memori. Selanjutnya, cosine similarity dihitung antar item (anime) berdasarkan pola rating pengguna. Fungsi get_collaborative_recommendations mengambil judul anime dan mengembalikan k anime lain yang paling mirip berdasarkan rating pengguna.

- Output menunjukkan 5 anime teratas yang direkomendasikan untuk "Death Note" berdasarkan pola rating pengguna yang serupa. "Code Geass: Hangyaku no Lelouch" memiliki skor kemiripan tertinggi (0.694266), diikuti oleh "Code Geass: Hangyaku no Lelouch R2", "Elfen Lied", "Shingeki no Kyojin", dan "Fullmetal Alchemist: Brotherhood", beserta skor kemiripannya. Rekomendasi ini didasarkan pada preferensi pengguna lain yang juga menyukai "Death Note".

# **Evaluation**
"""

# Evaluasi Content-Based (Relevansi Genre - Subjektif)
print("\nEvaluasi Content-Based (Relevansi Genre - Contoh):")
anime_title_eval_cb = "Shigatsu wa Kimi no Uso"
recommendations_cb_eval = get_content_based_recommendations(anime_title_eval_cb)
if recommendations_cb_eval is not None:
    print(f"Rekomendasi untuk '{anime_title_eval_cb}':")
    print(recommendations_cb_eval)

"""- Kode ini mengimplementasikan sistem rekomendasi Content-Based Filtering. Pertama, menggunakan TF-IDF untuk mengubah genre anime menjadi vektor numerik. Kemudian, menghitung kemiripan antar anime berdasarkan vektor genre menggunakan cosine similarity. Fungsi get_content_based_recommendations mengambil judul anime dan mengembalikan k anime paling mirip berdasarkan genre.

- Sistem rekomendasi Content-Based untuk anime "Shigatsu wa Kimi no Uso" berhasil merekomendasikan anime dengan genre yang relevan, seperti Drama, Music, Romance, dan School. Skor similaritas yang tinggi menunjukkan tingkat kemiripan genre yang baik antara anime input dan anime yang direkomendasikan.
"""

# Evaluasi Collaborative Filtering (Contoh - Melihat Anime dengan Rating Tinggi yang Mirip)
print("\nEvaluasi Collaborative Filtering (Anime Mirip dengan Rating Tinggi - Contoh):")

# Mencari anime dengan rating rata-rata tertinggi yang mungkin ada setelah filtering
top_rated_animes_after_filter = filtered_merged_df.groupby('name')['rating_user'].mean().sort_values(ascending=False).index

found_recommendations = False
for anime_title in top_rated_animes_after_filter:
    similar_to_top = get_collaborative_recommendations(anime_title)
    if similar_to_top is not None:
        print(f"Anime yang mirip dengan '{anime_title}':")
        print(similar_to_top)
        found_recommendations = True
        break # Hentikan setelah menemukan rekomendasi pertama

if not found_recommendations:
    print("Tidak ditemukan rekomendasi Collaborative Filtering untuk anime dengan rating tinggi setelah filtering.")

"""Sistem rekomendasi Collaborative Filtering, ketika dievaluasi dengan mencari anime yang mirip dengan anime berperingkat tinggi ('Kimi no Na wa.'), berhasil memberikan rekomendasi berdasarkan pola rating pengguna yang serupa. Anime-anime seperti 'Boku dake ga Inai Machi', 'Re:Zero kara Hajimeru Isekai Seikatsu', 'Shigatsu wa Kimi no Uso', 'ReLIFE', dan 'One Punch Man' direkomendasikan dengan skor kemiripan yang menunjukkan tingkat kesamaan preferensi pengguna. Hasil ini mengindikasikan bahwa Collaborative Filtering dapat mengidentifikasi anime yang mungkin disukai oleh pengguna berdasarkan riwayat rating pengguna lain."""

# Menampilkan top-N recommendation
print("\n--- Eksplorasi Parameter k (Jumlah Rekomendasi) ---")

anime_untuk_eksplorasi = "Naruto"
k_values_eksplorasi = [3, 5, 10]

print(f"\nEksplorasi untuk Anime: {anime_untuk_eksplorasi}")

for k in k_values_eksplorasi:
    # Content-Based
    recommendations_cb_k = get_content_based_recommendations(anime_untuk_eksplorasi, k=k)
    print(f"\nTop-{k} Rekomendasi Content-Based:")
    if recommendations_cb_k is not None:
        print(recommendations_cb_k.to_string())
    else:
        print("Anime tidak ditemukan.")

    # Collaborative Filtering
    recommendations_cf_k = get_collaborative_recommendations(anime_untuk_eksplorasi, k=k)
    print(f"\nTop-{k} Rekomendasi Collaborative Filtering:")
    if recommendations_cf_k is not None:
        print(recommendations_cf_k.to_frame(name='similarity_score').to_string()) # Mengubah Series ke DataFrame lalu output
    else:
        print("Anime tidak ditemukan dalam data rating yang difilter.")

"""- Content-Based Filtering: Untuk "Naruto", sistem Content-Based secara konsisten merekomendasikan sekuel, film, dan episode spesial dari seri "Naruto" itu sendiri dengan skor similaritas sempurna (1.0), karena mereka berbagi genre yang sama persis. Ketika k ditingkatkan menjadi 10, rekomendasi mulai mencakup anime lain dengan genre yang serupa namun tidak terkait langsung, seperti "Kyutai Panic Adventure!" dan "Naruto: Shippuuden Movie 6 - Road to Ninja", dengan skor similaritas yang sedikit lebih rendah.

- Collaborative Filtering: Rekomendasi dari Collaborative Filtering untuk "Naruto" sangat berbeda dan mencakup anime populer seperti "Death Note", "Sword Art Online", "Fullmetal Alchemist", "Code Geass", "Bleach", dan "Shingeki no Kyojin". Anime-anime ini direkomendasikan berdasarkan pola rating pengguna yang serupa dengan pengguna yang menyukai "Naruto". Skor similaritas dalam Collaborative Filtering relatif lebih rendah dibandingkan dengan Content-Based, menunjukkan tingkat kemiripan preferensi pengguna yang bervariasi.
"""

def calculate_precision_recall_k_single(recommendations, actual_relevant, k=10):
    """Menghitung precision@k dan recall@k untuk satu set rekomendasi."""
    if not recommendations:
        return 0, 0

    top_k_recommendations = set(recommendations[:k])
    relevant_in_top_k = len(actual_relevant.intersection(top_k_recommendations))
    precision = relevant_in_top_k / k
    recall = relevant_in_top_k / len(actual_relevant) if actual_relevant else 0
    return precision, recall

"""Sel ini mendefinisikan fungsi calculate_precision_recall_k yang akan digunakan oleh fungsi evaluasi utama."""

def evaluate_model_efficient(model_name, df, k_values=[5, 10], rating_threshold=7, sample_users=None):
    """Mengevaluasi model rekomendasi dengan lebih efisien."""
    user_anime_ratings = df.groupby('user_id')['anime_id'].apply(list)
    user_relevant_anime = {}
    for user_id in user_anime_ratings.index:
        user_relevant_anime[user_id] = set(df[(df['user_id'] == user_id) & (df['rating_user'] >= rating_threshold)]['anime_id'].unique())

    if sample_users is not None:
        users_to_evaluate = sample_users
    else:
        users_to_evaluate = user_anime_ratings.index

    all_precisions = defaultdict(list)
    all_recalls = defaultdict(list)

    for user_id in users_to_evaluate:
        watched_anime = user_anime_ratings.get(user_id, [])
        relevant_anime = user_relevant_anime.get(user_id, set())

        if not relevant_anime or not watched_anime:
            continue

        input_anime_name = df[df['anime_id'] == watched_anime[0]]['name'].iloc[0] if not df[df['anime_id'] == watched_anime[0]]['name'].empty else None
        if input_anime_name is None:
            continue

        if model_name == 'content_based':
            recommendations_df = get_content_based_recommendations(input_anime_name, k=max(k_values))
            if recommendations_df is not None:
                recommended_anime_ids = df_anime[df_anime['name'].isin(recommendations_df['name'])]['anime_id'].unique()
                recommendation_list = list(recommended_anime_ids)
                for k in k_values:
                    precision, recall = calculate_precision_recall_k_single(recommendation_list, relevant_anime, k=k)
                    all_precisions[f'precision@{k}'].append(precision)
                    all_recalls[f'recall@{k}'].append(recall)

        elif model_name == 'collaborative':
            recommendations_series = get_collaborative_recommendations(input_anime_name, k=max(k_values))
            if recommendations_series is not None:
                recommended_anime_names = recommendations_series.index.tolist()
                recommended_anime_ids = df[df['name'].isin(recommended_anime_names)]['anime_id'].unique()
                recommendation_list = list(recommended_anime_ids)
                for k in k_values:
                    precision, recall = calculate_precision_recall_k_single(recommendation_list, relevant_anime, k=k)
                    all_precisions[f'precision@{k}'].append(precision)
                    all_recalls[f'recall@{k}'].append(recall)

    mean_precisions = {k: np.mean(v) if v else 0 for k, v in all_precisions.items()}
    mean_recalls = {k: np.mean(v) if v else 0 for k, v in all_recalls.items()}

    return mean_precisions, mean_recalls

"""Fungsi evaluate_model_efficient mengukur kualitas sistem rekomendasi anime (CBF atau CF) dengan menghitung rata-rata precision@k dan recall@k pada sejumlah pengguna. Untuk setiap pengguna, fungsi ini membandingkan rekomendasi model dengan anime yang relevan bagi pengguna berdasarkan rating mereka. Outputnya adalah rata-rata precision dan recall untuk setiap k, yang menunjukkan seberapa akurat dan lengkap rekomendasi model."""

sample_size = 50 # Evaluasi pada 50 pengguna pertama
sample_users = filtered_merged_df['user_id'].unique()[:sample_size]

mean_precision_cb, mean_recall_cb = evaluate_model_efficient('content_based', filtered_merged_df, k_values=[5, 10], sample_users=sample_users)
print("\n--- Hasil Evaluasi Content-Based Filtering (Sample) ---")
for k in [5, 10]:
    print(f"Precision@{k}: {mean_precision_cb.get(f'precision@{k}', 0):.4f}")
    print(f"Recall@{k}: {mean_recall_cb.get(f'recall@{k}', 0):.4f}")

mean_precision_cf, mean_recall_cf = evaluate_model_efficient('collaborative', filtered_merged_df, k_values=[5, 10], sample_users=sample_users)
print("\n--- Hasil Evaluasi Collaborative Filtering (Sample) ---")
for k in [5, 10]:
    print(f"Precision@{k}: {mean_precision_cf.get(f'precision@{k}', 0):.4f}")
    print(f"Recall@{k}: {mean_recall_cf.get(f'recall@{k}', 0):.4f}")

"""Kode yang telah dieksekusi bertujuan untuk mengevaluasi kinerja dua pendekatan sistem rekomendasi anime: Content-Based Filtering (CBF) dan Collaborative Filtering (CF). Evaluasi dilakukan dengan menghitung metrik precision@k dan recall@k pada sampel acak 50 pengguna dari dataset.

Untuk model Content-Based Filtering, hasil evaluasi menunjukkan precision@5 sebesar 0.1174 dan recall@5 sebesar 0.0077. Ini berarti bahwa dari 5 rekomendasi teratas yang diberikan oleh model CBF, sekitar 11.74% di antaranya relevan dengan preferensi pengguna. Sementara itu, model CBF berhasil merekomendasikan sekitar 0.77% dari total anime yang relevan bagi pengguna dalam 5 rekomendasi teratasnya. Pada k=10, precision menurun menjadi 0.0718, dan recall meningkat menjadi 0.0102.

Untuk model Collaborative Filtering, hasil evaluasi pada sampel yang sama menunjukkan kinerja yang lebih rendah dibandingkan CBF. Precision@5 tercatat sebesar 0.0308 dan recall@5 sebesar 0.0020. Ini mengindikasikan bahwa hanya sekitar 3.08% dari 5 rekomendasi teratas CF yang relevan, dan model ini hanya mencakup 0.20% dari total anime yang relevan dalam 5 rekomendasi teratasnya. Pada k=10, precision menjadi 0.0204 dan recall menjadi 0.0027.

Insight dari Output Kode:

  - Performa Relatif Model: Pada sampel 50 pengguna ini, model Content-Based Filtering secara signifikan mengungguli model Collaborative Filtering dalam hal precision dan recall. Ini menunjukkan bahwa berdasarkan fitur konten anime yang digunakan (kemungkinan judul dan/atau genre), model CBF lebih baik dalam memberikan rekomendasi yang relevan bagi pengguna dibandingkan dengan model CF dengan konfigurasi saat ini.

  - Akurasi Rekomendasi Awal (Precision): Precision yang lebih tinggi pada CBF mengindikasikan bahwa rekomendasi teratasnya lebih akurat dan cenderung sesuai dengan preferensi pengguna dibandingkan dengan rekomendasi dari CF.

  - Kemampuan Menangkap Seluruh Item Relevan (Recall): Nilai recall yang rendah untuk kedua model menunjukkan bahwa keduanya masih memiliki keterbatasan dalam mencakup seluruh anime yang mungkin relevan bagi pengguna. Ini bisa menjadi area untuk perbaikan lebih lanjut.

  - Pengaruh Nilai K: Seperti yang umum terjadi, precision cenderung menurun dan recall cenderung meningkat saat nilai k (jumlah rekomendasi yang dipertimbangkan) bertambah.

  - Potensi Masalah pada CF: Kinerja CF yang jauh lebih rendah mungkin disebabkan oleh sparsity data rating, masalah cold start, atau implementasi algoritma CF yang kurang optimal untuk dataset ini. Perlu dilakukan analisis lebih lanjut pada implementasi CF dan karakteristik data interaksi pengguna.

  - Validitas Sampel: Penting untuk diingat bahwa hasil ini didasarkan pada sampel 50 pengguna. Evaluasi pada sampel yang lebih besar atau seluruh dataset akan memberikan gambaran kinerja yang lebih stabil dan representatif.

Secara keseluruhan, output kode memberikan indikasi awal bahwa Content-Based Filtering mungkin menjadi pendekatan yang lebih efektif untuk sistem rekomendasi anime pada dataset ini, setidaknya dengan konfigurasi model saat ini. Namun, perlu dilakukan eksplorasi lebih lanjut untuk meningkatkan kinerja Collaborative Filtering.
"""